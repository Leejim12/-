{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10268\\3904754002.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[1;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[0;32m   6153\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Enabling eager execution\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6154\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6155\u001b[1;33m     return enable_eager_execution_internal(\n\u001b[0m\u001b[0;32m   6156\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6157\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[1;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[0;32m   6221\u001b[0m         _default_graph_stack._global_default_graph is not None)  # pylint: disable=protected-access\n\u001b[0;32m   6222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6223\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   6224\u001b[0m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0;32m   6225\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "enable_eager_execution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공지능, 딥러닝\n",
    "- 인공지능 기본 키워드\n",
    "```\n",
    "자연어처리(음성인식)\n",
    "인공신경만\n",
    "퍼지로직\n",
    "로보틱스\n",
    "컴퓨터 비전\n",
    "패턴인식\n",
    "기계학습\n",
    "딥러닝\n",
    "```\n",
    "\n",
    "- 기계학습\n",
    ": 인간과 같이 학습할 수 있도록.\n",
    "\n",
    "- 딥러닝\n",
    ": 층을 쌓아 학습하는 기계학습 분야."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감독학습, 무감독학습, 강화학습\n",
    "- 감독학습\n",
    ": 정답 레이블 있는 데이터 셋 사용.\n",
    "=> 입력에 대해 기대되는 목표값 사용. 오차 최소화.\n",
    "ex) 물체 인식, 분류 등에 사용.\n",
    "\n",
    "- 무감독학습\n",
    ": 레이블 없는 데이터셋 사용. 유사한 특징 가지는 데이터의 분포, 군집, 분할 등을 계산.\n",
    "ex) k-mean 클러스터링 알고리즘.\n",
    "\n",
    "- 강화학습\n",
    ": 환경과 상호작용 하면서, 누적 보상을 최대화하기 위한 상태에서 최적의 행동인 정책 학습.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우 설치\n",
    "\n",
    "1. 텐서플로우 CPU 버전 \n",
    "```\n",
    "pip install tensorflow-cpu\n",
    "```\n",
    "* cpu 버전은 CUDA toolkit, cuDNN 설치 x\n",
    "  - CUDA : 그래픽\n",
    "  - cuDNN : 딥러닝 가속 라이브러리\n",
    "\n",
    "2. 기타 관련 패키지 설치\n",
    "```\n",
    "pip -m install --upgrade pip\n",
    "pip install tensorflow\n",
    "pip install pilow\n",
    "pip install opencv-python\n",
    "pip install matplotlib\n",
    "```\n",
    "\n",
    "3. 환경변수 설정\n",
    "```\n",
    "변수 이름 : CUDA_PATH_V10_1\n",
    "변수 값 : C:\\Program Files\\NVDIA GPU Computing Toolkit\\CUDA\\v10.1\n",
    "```\n",
    "* XLA_CPU, XLA_GPU : CUDA 커널 지원하기 위한 가속선형대수 최적화 컴파일러\n",
    "\n",
    "* GPU 할당 관련\n",
    "=> 코랩에서 실행 시 오류 없으니, PC 환경에 따라 GPU 할당 문제 생길 수 있음.\n",
    "=> 해결방법\n",
    "```\n",
    "# 1. 메모리 확장 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "\n",
    "# 2. 메모리 제한 설정\n",
    "gpus = tf.config.experimental.list_physical_device('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "  gpus[0],\n",
    "  [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    ")\n",
    "```\n",
    "  1. 메모리 확장 설정\n",
    "  : tf.config.experimental.set_memory_growth()\n",
    "  ==> 메모리 증가를 허용. 초기에는 GPU 조금만 할당\n",
    "  ==> 더 많이 필요할떄 tf에 할당된 GPU영역을 확장.\n",
    "\n",
    "  2. tf.config.experimental.set_virtual_device_configuration()\n",
    "  ==> GPU로 메모리 사용 제한."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2장. 텐서플로 기초"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 즉시 실행모드와 텐서 생성.\n",
    "즉시실행 모드 활성화 => tf.Session() 생성 않고도 실행 가능."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉시실행모드 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "tf.executing_eagerly()  # True : 즉시 실행모드 활성화 되어있음.\n",
    "\n",
    "# disable_eager_execution() # 즉시실행모드 비활성화 메소드\n",
    "tf.executing_eagerly()  # False : 즉시 실행모드 비활성화 되어있음."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 생성 (tf.constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Const_2:0\", shape=(), dtype=int32)\\n:\\nTensor(\"Const_3:0\", shape=(), dtype=int32)\\nTensor(\"add_1:0\", shape=(), dtype=int32)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 Graph construction\n",
    "a = tf.constant(1)  # 정수형 텐서 생성 (값 할당 x)\n",
    "b = tf.constant(2)  # 정수형 텐서 생성 (값 할당 x)\n",
    "c = a + b           # 계산 그래프 생성\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\"\"\"\n",
    "Tensor(\"Const_2:0\", shape=(), dtype=int32)\n",
    ":\n",
    "Tensor(\"Const_3:0\", shape=(), dtype=int32)\n",
    "Tensor(\"add_1:0\", shape=(), dtype=int32)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Graph execution\n",
    "sess = tf.compat.v1.Session()\n",
    "sess.run(a)\n",
    "sess.run(b)\n",
    "sess.run(c)\n",
    "## 세션 만들어서 실행 => 텐서 값 반환\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(1)  # 정수형 텐서 생성 (값 할당 x)\n",
    "b = tf.constant(2)  # 정수형 텐서 생성 (값 할당 x)\n",
    "c = a + b           # 계산 그래프 생성\n",
    "\n",
    "a.numpy(),b.numpy(),c.numpy()   # (1, 2, 3) => numpy 영역에 값이 있음을 알 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 3])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant(1)\n",
    "b = tf.constant([1,2,3,4])\n",
    "c = tf.constant([[1,2],[3,4]])\n",
    "d = tf.constant([[[1,2],[3,4]]])\n",
    "\n",
    "a   # <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
    "b   # <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])>\n",
    "c\n",
    "# <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
    "# array([[1, 2],\n",
    "#        [3, 4]])>\n",
    "d\n",
    "# <tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
    "# array([[[1, 2],\n",
    "#         [3, 4]]])>\n",
    "\n",
    "## 타입만 보고싶을땐?\n",
    "a.dtype     # tf.int32\n",
    "\n",
    "## 차원 보고싶을땐?\n",
    "a.ndim, b.ndim, c.ndim, d.ndim    # (0, 1, 2, 3)\n",
    "\n",
    "## 인덱싱, 슬라이싱 되나?\n",
    "b[0]\n",
    "b[:2]\n",
    "c[0,0]\n",
    "c[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서생성 (tf.Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.Variable(1)\n",
    "b = tf.Variable([1,2,3,4])\n",
    "c = tf.Variable([[1,2],[3,4]])\n",
    "d = tf.Variable([[[1,2],[3,4]]])\n",
    "\n",
    "a.dtype   # tf.int32\n",
    "## tf.Variable로 생성해도 dtype 은 같음.\n",
    "\n",
    "a.shape, b.shape,c.shape,d.shape\n",
    "# (TensorShape([]),\n",
    "#  TensorShape([4]),\n",
    "#  TensorShape([2, 2]),\n",
    "#  TensorShape([1, 2, 2]))\n",
    "\n",
    "a #<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>\n",
    "a.trainable   # True : tf.Variable로 생성한 변수는 훈련가능함.\n",
    "\n",
    "## 인덱싱, 슬라이싱은 constant 랑 동일하게 다 된다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.zeros(),tf.ones(),tf.zeros_like(),tf.ones_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.zeros(shape=(2,3))\n",
    "a\n",
    "# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
    "# array([[0., 0., 0.],\n",
    "#        [0., 0., 0.]], dtype=float32)>\n",
    "## default dtype = float32\n",
    "\n",
    "b = tf.ones(shape=(2,3))\n",
    "b\n",
    "# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
    "# array([[1., 1., 1.],\n",
    "#        [1., 1., 1.]], dtype=float32)>\n",
    "\n",
    "c = tf.zeros_like(b)\n",
    "c\n",
    "# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
    "# array([[0., 0., 0.],\n",
    "#        [0., 0., 0.]], dtype=float32)>\n",
    "\n",
    "d = tf.ones_like(c)\n",
    "d\n",
    "# <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
    "# array([[1., 1., 1.],\n",
    "#        [1., 1., 1.]], dtype=float32)>\n",
    "\n",
    "w = tf.Variable(d)\n",
    "w\n",
    "# <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
    "# array([[1., 1., 1.],\n",
    "#        [1., 1., 1.]], dtype=float32)>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.fill(),tf.linspace(), tf.range(),tf.ones_lie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(8,) dtype=float32, numpy=array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.fill([2,3],2) ## [2,3] 크기에 2를 채움,\n",
    "a\n",
    "# <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
    "# array([[2, 2, 2],\n",
    "#        [2, 2, 2]])>\n",
    "\n",
    "b = tf.linspace(0.0,1.0,5)\n",
    "b\n",
    "# <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0.  , 0.25, 0.5 , 0.75, 1.  ], dtype=float32)>\n",
    "# 0.0~1.0까지 0.5개 만듬(등간격)\n",
    "\n",
    "c = tf.range(5) \n",
    "c\n",
    "# <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4])>\n",
    "\n",
    "d = tf.range(1,5,0.5)\n",
    "d\n",
    "# <tf.Tensor: shape=(8,), dtype=float32, numpy=array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5], dtype=float32)>\n",
    "## 1~5까지 0.5씩. (5 미포함)\n",
    "\n",
    "w = tf.Variable(d)\n",
    "## 텐서d로 초기화된 1차원 텐서 변수 w 생성.\n",
    "w\n",
    "# <tf.Variable 'Variable:0' shape=(8,) dtype=float32, numpy=array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5], dtype=float32)>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.reshape(), tf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[0, 3],\n",
       "       [1, 4],\n",
       "       [2, 5]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.range(6)\n",
    "a\n",
    "# <tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5])>\n",
    "b = tf.reshape(a,shape=(2,3))\n",
    "b\n",
    "# <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
    "# array([[0, 1, 2],\n",
    "#        [3, 4, 5]])>\n",
    "c = tf.reshape(b,shape=(-1,))\n",
    "c\n",
    "# <tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5])>\n",
    "\n",
    "d = tf.transpose(b)\n",
    "d\n",
    "# <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
    "# array([[0, 3],\n",
    "#        [1, 4],\n",
    "#        [2, 5]])>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.concat(), tf.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1,2])\n",
    "b = tf.constant([3,4])\n",
    "c = tf.concat([a,b],axis=0)\n",
    "\n",
    "tf.stack([a,b]) ## 걍 두개 연결 [[1,2],[3,4]]\n",
    "tf.stack([a,b],axis=1) ## 이거 사실 디폴트임. 위에꺼랑 결과 같음.\n",
    "tf.concat([a,b],axis=0) ## 같은 축에 연결함. [1,2,3,4]\n",
    "# <tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 2, 3, 4])>\n",
    "\n",
    "tf.concat([c,b],axis=0)\n",
    "# <tf.Tensor: shape=(6,), dtype=int32, numpy=array([1, 2, 3, 4, 3, 4])>\n",
    "\n",
    "b = tf.reshape(b,shape=(2,1))\n",
    "b\n",
    "# <tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
    "# array([[3],\n",
    "      #  [4]])>\n",
    "      \n",
    "tf.concat([c,b],axis=1) ### 옆으로 붙임.\n",
    "\n",
    "### concat : axis = 0 => 아래로 붙임\n",
    "###          axis = 1 => 옆으로 붙임."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.expand()_dims(), tf.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[1, 2]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([1,2])\n",
    "a\n",
    "\n",
    "b = tf.expand_dims(a,axis=0)      # 한 차원 확장. (그냥 괄호 씌움)\n",
    "b\n",
    "\n",
    "c = tf.expand_dims(a,axis=1)      # 한 차원 확장. (a의 요소들을 쪼개서, 걔들을 각각 원소로 가지는 차원으로 확장)\n",
    "c\n",
    "\n",
    "d = tf.expand_dims(c,axis=0)\n",
    "d\n",
    "\n",
    "e = tf.squeeze(d)\n",
    "e  \n",
    "# <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2])>\n",
    "\n",
    "f = tf.squeeze(d,axis=2) ### 2번째 축 삭제\n",
    "f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[-1.1771783 , -0.90325946,  0.8419609 ],\n",
       "       [-0.06870949,  0.33911815, -0.9542566 ]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(1) # 난수 값 초기화\n",
    "a = tf.range(5)\n",
    "\n",
    "tf.random.shuffle(a)\n",
    "tf.random.uniform(shape=(2,3),minval=0,maxval=1)\n",
    "### 0~1사이 균등분포 초기화\n",
    "\n",
    "tf.random.normal(shape=(2,3))\n",
    "### mean = 0, stddev = 1짜리\n",
    "\n",
    "tf.random.normal(shape=(2,3),mean=10,stddev=2)\n",
    "\n",
    "tf.random.truncated_normal(shape=(2,3))\n",
    "# 난수로 초기화된 (2,3)크기\n",
    "\n",
    "w = tf.Variable(tf.random.truncated_normal(shape=(2,3)))\n",
    "w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서플로 사칙연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1., 1.],\n",
       "       [3., 2.]])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant([1,2])\n",
    "## 기본 연산들 :: a의 모든 인자들에 대해 연산을 수행\n",
    "a+1 #[2,3]\n",
    "a-1 #[0,1]\n",
    "a*2\n",
    "a/2\n",
    "\n",
    "b = tf.constant([3,4])\n",
    "a+b\n",
    "a-b\n",
    "a*b\n",
    "a/b\n",
    "\n",
    "a = tf.constant([[1,2],[3,4]])\n",
    "b = tf.constant([1,2])\n",
    "a+b ## tf.add(a,b)\n",
    "a-b ## tf.subtract(a,b) ## [[0,0],[2,2]]\n",
    "a*b\n",
    "a/b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min,max,sum,prod,mean,argmin,argmax,sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int32)\n",
      "tf.Tensor([0 4 8], shape=(3,), dtype=int32)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor([ 8  9 10 11], shape=(4,), dtype=int32)\n",
      "tf.Tensor([ 3  7 11], shape=(3,), dtype=int32)\n",
      "tf.Tensor(66, shape=(), dtype=int32)\n",
      "tf.Tensor([12 15 18 21], shape=(4,), dtype=int32)\n",
      "tf.Tensor([ 6 22 38], shape=(3,), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor([4 5 6 7], shape=(4,), dtype=int32)\n",
      "tf.Tensor([1 5 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.reshape(tf.range(12),shape=(3,4))\n",
    "\n",
    "print(tf.reduce_min(a)) ## [0, 4, 8] ## default :: axis=1\n",
    "print(tf.reduce_min(a,axis=0))\n",
    "print(tf.reduce_min(a,axis=1))\n",
    "\n",
    "## 똑같은 내용에서 최대값 계산.\n",
    "print(tf.reduce_max(a))\n",
    "print(tf.reduce_max(a,axis=0))\n",
    "print(tf.reduce_max(a,axis=1))\n",
    "\n",
    "print(tf.reduce_sum(a))\n",
    "print(tf.reduce_sum(a,axis=0))\n",
    "print(tf.reduce_sum(a,axis=1))\n",
    "\n",
    "print(tf.reduce_mean(a))\n",
    "print(tf.reduce_mean(a,axis=0)) ## 아래방향 평균\n",
    "print(tf.reduce_mean(a,axis=1)) ## 옆방향 평균\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
